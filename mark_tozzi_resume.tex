% LaTeX file for resume
% This file uses the resume document class (res.cls)

\documentclass[margin]{res}
% the margin option causes section titles to appear to the left of body text
\textwidth=5.2in % increase textwidth to get smaller right margin
\usepackage{hyperref}
\hypersetup{colorlinks=true,urlcolor=blue}

% Center align address.  See http://tex.stackexchange.com/questions/94204/using-the-res-cls-latex-file-how-do-i-centre-the-address
\makeatletter
\def\@tablebox#1{\begin{tabular}[t]{@{}c@{\extracolsep{\fill}}}#1\end{tabular}}
\makeatother


\begin{document}

\name{Mark Tozzi}

\address{Baltimore, MD --- (917) 678 3636 \\
\href{mailto:mark.tozzi@gmail.com}{mark.tozzi@gmail.com}
$\bullet$ \href{https://github.com/not-napoleon}{github: not-napoleon}
$\bullet$ \href{https://twitter.com/not_napoleon}{twitter: not\_napoleon} }


\begin{resume}

\section{Summary}
I am a software engineer with over a decade of experience, most of it working
fully remote, in the data engineering space.  I've focused on building high
throughput data pipelines for a range of applications and shapes of data.
I have been involved in every step of developing a data-driven application,
from architecture and planning through implementation to maintenance and
monitoring.  I love solving hard problems and finding ways to make data
available to users in a meaningful way.

% Tabulate Computer Skills; p{3in} defines paragraph 3 inches wide
\section{Software \& \\ Languages}
   \begin{tabular}{l p{3in}}
     \underline{Languages:} & Python, Perl, SQL, Java, Shell scripting\\
     \underline{Databases:} & Postgres, MySQL, Redis, MS SQL Server \\
     \underline{Other Tools:} & Kafka, Spark, Hadoop, Lucene
   \end{tabular}

\raggedright{}
\section{Experience}
 {\bf Senior Developer,} Solar Winds, Remote \hfill November 2017--Present
    \begin{itemize}
        \item Worked with teams from multiple acquired companies to build out
            a unified cloud offering.
        \item Worked on metrics ingestion back end in Java, using DropWizard
            for REST endpoints and gRPC for internal calls.
        \item Maintained and expanded legacy ETL tool for Amazon CloudWatch
            metrics.
        \item Standardized billing logic across multiple components.
    \end{itemize}
 {\bf Platform Developer,} Rocana, Remote \hfill November 2015--October 2017
\begin{itemize}
    \item Collaborated with a fully remote team spanning four timezones
    \item Worked on distributed full text search system using time sharded
        Lucene indexes stored in HDFS
    \item Built and debugged ETL pipeline to ingest records from Kafka
        and index them into Lucene
    \item Forked and maintained Solr HDFS classes, including the BlockCache
    \item Used both code analysis and log analysis techniques to debug subtle
        threading issues in highly multi-threaded, callback based, architecture
    \item Employed pair programming techniques working with teammates to debug
        issues
    \item Advocated for, designed and built the first set of automated fault
        injection tests at the company.
    \item Worked on a batch query report framework using Spark Sql
    \item Worked with customer support to resolve tier 3 escalations in a
        timely fashion.
    \item Participated in customer support calls during escalations
    \item Partnered with project managers to break features down into tickets
        and plan milestone scopes
\end{itemize}

 {\bf Senior Developer,} Keep.com, Remote \hfill 2012--2015
\begin{itemize}
  \item Worked remotely in small team environment to develop and support
      consumer facing web applications for New York based startup
  \item Initiated web crawler project and grew it to a team of 4, crawling
    over 1 million pages twice a day, using Celery and Flask to manage job
    requests and returning data
  \item Built machine learning models and web scraping tools using
    scikit-learn and beautiful soup to analyze and extract information from
    retailer websites and emails
  \item Developed data models in Python to interface with both Postgres and
    Redis data stores
  \item Designed and implemented custom internal A/B testing framework,
    including integration with existing Mixpanel based reporting for data
    collection
  \item Led successful effort to integrate Etsy's Statsd system as a central
    broker for tracking internal metrics
  \item Designed and implemented auto-complete system using Redis sorted sets
    with multi-tiered sorting based on a custom algorithm
  \item Built ``accounting style'' active user tracking system using Redis bit
    sets for minimal data footprint; we released a general implementation of
    this system as an open source project:
    \href{https://github.com/saltmine/redis-gadgets}{redis-gadgets}
  \item Migrated from pure Redis backend to hybrid Redis/Postgres backend,
      with no data loss and minimal downtime
  \item Practiced Test Driven Development (TDD) to dramatically lower the
      defect rate in released code.  Converted several other team members to
      the TDD methodology
  \item Mentored team members in code style and design
\end{itemize}

{\bf Senior Analytics Engineer,} Adkeeper Networks, Remote \hfill  2010--2012
\begin{itemize}
  \item Built batch processing analytics system based on Hadoop, using Pig
      scripts for ETL operations.
  \item Maintained suite of junit-based integration tests for import and
      export of data.
  \item Diagnosed and helped to solve operational problems with delivery of
      tens of gigabytes of log data from several systems
\end{itemize}

{\bf Developer,} About.com, New York, NY \hfill  2006--2010
\begin{itemize}
  \item Supported a custom built site usage tracking system which processed
    over 60 Gigabytes of data daily from 90 servers in 3 data centers
  \item Designed and implemented a major new metrics system using the Apache
    Hadoop framework, Apache Hive, and MapReduce to feed data into a MySQL data
    warehouse
  \item Wrote Mapper and Reducer functions in Java for Hadoop framework,
    including JUnit based unit tests
  \item Wrote Perl scripts for interfacing with Oracle, SQL Server, and
    MySQL databases
  \item Provided data feeds for business critical applications including
    inventory availability and payroll
  \item Built and maintained database triggers in PL/SQL to ensure data
    consistency and integrity
  \item Supported over 600 users across three divisions
  \item Collaborated with users and project manager to define project requirements
      and build detailed specifications
\end{itemize}

\section{Education}
Bachelor of Science in Computer Science, Polytechnic University, Brooklyn New
York, 2003

\end{resume}
\end{document}
